{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set debug\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "def one_hot_encode(labels):\n",
    "    n_labels=len(labels)\n",
    "    #set_trace() #debug\n",
    "    n_unique_labels=len(np.unique(labels))\n",
    "    one_hot_encode =np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels]=1\n",
    "    return one_hot_encode\n",
    "def read_DataSet(fileName):\n",
    "    df = pd.read_csv(fileName)\n",
    "    #last column is label\n",
    "    set_trace() #debug\n",
    "    rows,cols = df.shape\n",
    "    X = df[df.columns[0:cols-1]].values\n",
    "    Y = df[df.columns[cols-1]]\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(Y)\n",
    "    Y = encoder.transform(Y)\n",
    "    coded_Y = one_hot_encode(Y)\n",
    "    \n",
    "    print(X.shape)\n",
    "    return (X,coded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataFile=\"sonar.all-data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y=read_DataSet(dataFile);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,Y = shuffle(X,Y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y = train_test_split(X,Y,test_size=0.2, random_state=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"training set x shape\",(train_x.shape))\n",
    "print(\"training set y shape\",train_y.shape)\n",
    "print(\"testing set x shape\", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate=0.3\n",
    "training_epoches=1000\n",
    "cost_history=np.empty(shape=[1], dtype=float)\n",
    "n_dim=X.shape[1]\n",
    "print (\"dimension {0}\".format(n_dim))\n",
    "n_class=2\n",
    "model_path=\"NMI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define number of hidden layer\n",
    "n_hidden_1=60\n",
    "n_hidden_2=60\n",
    "n_hidden_3=60\n",
    "n_hidden_4=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define the input parameters with column vector n_dim as dimesion\n",
    "x = tf.placeholder(tf.float32, [None,n_dim])\n",
    "W = tf.Variable(tf.zeros([n_dim,n_class]))\n",
    "b = tf.Variable(tf.zeros([n_dim]))\n",
    "real_y = tf.placeholder(tf.float32, [None,n_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define the Model\n",
    "def multilayer_perceptron ( x,weights, biases):\n",
    "    #Hidden layer with RELU activation\n",
    "    layer_1=tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    layer_1 = tf.nn.sigmoid(layer_1)\n",
    "    \n",
    "    #Hidden layer with sigmoid activation\n",
    "    layer_2 = tf.add(    tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
    "    layer_2 = tf.nn.sigmoid(layer_2)\n",
    "\n",
    "    #Hidden layer with sigmoid activation\n",
    "    layer_3 = tf.add(    tf.matmul(layer_2,weights['h3']),biases['b3'])\n",
    "    layer_3 = tf.nn.sigmoid(layer_3)\n",
    "    \n",
    "    #Hidden layer with sigmoid activation\n",
    "    layer_4 = tf.add(    tf.matmul(layer_3,weights['h4']),biases['b4'])\n",
    "    layer_4 = tf.nn.relu(layer_4)\n",
    "    \n",
    "    #output layer with linear activation\n",
    "    #out_layer = tf.add(tf.matmul(layer_4,weights['out']),biases['out'])\n",
    "    #out_layer = tf.nn.softmax(out_layer)\n",
    "    out_layer = tf.matmul(layer_4,weights['out'])+biases['out']\n",
    "    \n",
    "    return out_layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights={\n",
    "    'h1':tf.Variable(    tf.truncated_normal([n_dim,n_hidden_1])),\n",
    "    'h2':tf.Variable(    tf.truncated_normal([n_hidden_1,n_hidden_2])),\n",
    "    'h3':tf.Variable(    tf.truncated_normal([n_hidden_2,n_hidden_3])),\n",
    "    'h4':tf.Variable(    tf.truncated_normal([n_hidden_3,n_hidden_4])),\n",
    "    'out':tf.Variable(    tf.truncated_normal([n_hidden_4,n_class]))\n",
    "}\n",
    "biases = {\n",
    "    'b1':tf.Variable(    tf.truncated_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(    tf.truncated_normal([n_hidden_2])),\n",
    "    'b3':tf.Variable(    tf.truncated_normal([n_hidden_3])),\n",
    "    'b4':tf.Variable(    tf.truncated_normal([n_hidden_4])),\n",
    "    'out':tf.Variable(    tf.truncated_normal([n_class]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_y = multilayer_perceptron(x,weights,biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#implementation the linear lost function: SUM( real_y - predicted_y{activatefunc(linear weight dot product + bias)})/N\n",
    "cost_function=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predicted_y, labels=real_y))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_history=[]\n",
    "accuracy_history=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sess = tf.Session()\n",
    "#sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sess.run(training_step,feed_dict={x:train_x,real_y:train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#r=sess.run(tf.argmax(predicted_y,1),feed_dict={x:train_x,real_y:train_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#r=sess.run(tf.argmax(real_y,1),feed_dict={x:train_x,real_y:train_y})\n",
    "#sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(training_epoches):\n",
    "        sess.run(training_step,feed_dict={x:train_x,real_y:train_y})\n",
    "        cost = sess.run(cost_function,feed_dict={x:train_x,real_y:train_y})\n",
    "        cost_history = np.append(cost_history,cost)\n",
    "        correct_prediction = tf.equal(tf.argmax(predicted_y,1),tf.argmax(real_y,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "        \n",
    "        pred_y = sess.run(predicted_y, feed_dict={x:test_x})\n",
    "        mse = tf.reduce_mean(tf.square(pred_y-test_y))\n",
    "        mse_ = sess.run(mse)\n",
    "        mse_history.append(mse_)\n",
    "        accuracy = (sess.run(accuracy,feed_dict={x:train_x,real_y:train_y}))\n",
    "        accuracy_history.append(accuracy)\n",
    "        print (\"epoch: {0} - cost: {1} - MSE: {2} - Train Accuracy: {3}\".format(epoch,cost,mse_,accuracy))\n",
    "    save_path = saver.save(sess,model_path)\n",
    "    print(\"Saved model in file {0}\".format(save_path))\n",
    "    \n",
    "    #Print the final accuracy\n",
    "    test_correct_prediction =tf.equal(tf.argmax(pred_y,1),tf.argmax(test_y,1))\n",
    "    test_accuracy = tf.reduce_mean(tf.cast(test_correct_prediction,tf.float32))\n",
    "    print(\"Test accuracy:{0}\",(sess.run(test_accuracy,feed_dict={x:train_x,real_y:train_y})))\n",
    "    mse = tf.reduce_mean(tf.square(pred_y-test_y))\n",
    "    print (\"MSE : {0}\".format(mse))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(mse_history,'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(accuracy_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reload the saved model and run testing\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "saver.restore(sess,\"./NMI\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
